import shutil

import cv2
import numpy as np
import torch
import os
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.nn.functional as F
from tqdm import tqdm
from itertools import cycle
from data.build_dataset import build_dataset
from models.build_model import build_model
from models.dc_gan import DCGAN_D
from utils.evaluate import evaluate
from opt import args
from utils.loss import BceDiceLoss, sigmoid_rampup, SemanticContrastiveLoss, dynamic_edge_loss, get_boundary_sobel
import math
import warnings
from utils.loss import edge_loss

warnings.filterwarnings("ignore", category=UserWarning)


def DeepSupSeg(pred, gt):
    criterion = BceDiceLoss()
    loss = criterion(pred, gt)
    return loss


def get_boundary_map(mask_batch):
    """
    Extract boundary map using Sobel operator as described in the paper.
    This replaces Canny edge detection to match the paper's methodology.
    """
    return get_boundary_sobel(mask_batch)


def lr_poly(base_lr, iter, max_iter, power):
    return base_lr * ((1 - float(iter) / max_iter) ** power)


def adjust_lr_rate(argsimizer, iter, total_batch):
    lr = lr_poly(args.lr, iter, args.nEpoch * total_batch, args.power)
    argsimizer.param_groups[0]['lr'] = lr
    return lr


def train():
    """load data"""
    train_l_data, _, valid_data = build_dataset(args)
    train_l_dataloader = DataLoader(train_l_data, args.batch_size, shuffle=True, num_workers=args.num_workers)
    valid_sign = False
    if valid_data is not None:
        valid_sign = True
        valid_dataloader = DataLoader(valid_data, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)
        val_total_batch = math.ceil(len(valid_data) / args.batch_size)

    """load model"""
    model = build_model(args)

    optim = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

    # train
    print('\n---------------------------------')
    print('Start training')
    print('---------------------------------\n')

    F1_best, F1_second_best, F1_third_best = 0, 0, 0
    best = 0
    for epoch in range(args.nEpoch):
        model.train()

        print("Epoch: {}".format(epoch))
        total_batch = math.ceil(len(train_l_data) / args.batch_size)
        bar = tqdm(enumerate(train_l_dataloader), total=total_batch)
        for batch_id, data_l in bar:
            itr = total_batch * epoch + batch_id
            img, gt = data_l['image'], data_l['label']
            if args.GPUs:
                img = img.cuda()
                gt = gt.cuda()
            optim.zero_grad()
            mask = model(img)
            loss = DeepSupSeg(mask, gt)
            loss.backward()
            optim.step()
            adjust_lr_rate(optim, itr, total_batch)

        if valid_sign == True:
            recall, specificity, precision, F1, F2, \
                ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice = evaluate(model, valid_dataloader, val_total_batch)

            print("Valid Result:")
            print(
                'recall: %.4f, specificity: %.4f, precision: %.4f, F1: %.4f, F2: %.4f, ACC_overall: %.4f, IoU_poly: %.4f, IoU_bg: %.4f, IoU_mean: %.4f, dice: %.4f' \
                % (recall, specificity, precision, F1, F2, ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice))

            if dice > best:
                best = dice
            print("Best Dice:: ", best)

            if (F1 > F1_best):
                F1_best = F1
                torch.save(model.state_dict(), args.root + "/semi/checkpoint/" + args.ckpt_name + "/best.pth")
            elif (F1 > F1_second_best):
                F1_second_best = F1
                torch.save(model.state_dict(), args.root + "/semi/checkpoint/" + args.ckpt_name + "/second_best.pth")
            elif (F1 > F1_third_best):
                F1_third_best = F1
                torch.save(model.state_dict(), args.root + "/semi/checkpoint/" + args.ckpt_name + "/third_best.pth")

def train_semi():
    """
    SCRAæ¡†æ¶çš„åŠç›‘ç£è®­ç»ƒå‡½æ•°
    
    è®­ç»ƒæµç¨‹æ¦‚è¿°ï¼ˆå¯¹åº”è®ºæ–‡ç¬¬3èŠ‚ï¼‰ï¼š
    1. æ•°æ®åŠ è½½ï¼šæ ‡æ³¨æ•°æ®D_lå’Œæ— æ ‡æ³¨æ•°æ®D_u
    2. æ¨¡å‹åˆå§‹åŒ–ï¼š
       - ä¸»åˆ†å‰²ç½‘ç»œï¼ˆåŒ…å«CAå¢å¼ºçš„ç¼–ç å™¨å’ŒåŒè§£ç å™¨ï¼‰
       - SCDåˆ¤åˆ«å™¨ï¼ˆç”¨äºç»“æ„å¯¹æ¯”å­¦ä¹ ï¼‰
    3. æ¯ä¸ªè®­ç»ƒè¿­ä»£ï¼š
       a) æ ‡æ³¨æ•°æ®ï¼šè®¡ç®—ç›‘ç£æŸå¤±L_supï¼ˆBCE + Dice + è¾¹ç•ŒæŸå¤±ï¼‰
       b) æ— æ ‡æ³¨æ•°æ®ï¼š
          - ç”Ÿæˆä¼ªæ ‡ç­¾mask_boud
          - SCDæ¨¡å—ï¼šè®¡ç®—å¯¹æŠ—æŸå¤±L_advå’Œç‰¹å¾åŒ¹é…æŸå¤±L_FMï¼ˆç¬¬3.2èŠ‚ï¼‰
          - SORæ¨¡å—ï¼šè®¡ç®—ç»“æ„ä¸€è‡´æ€§æŸå¤±L_SORï¼ˆç¬¬3.5èŠ‚ï¼‰
          - å…¶ä»–è¾…åŠ©æŸå¤±ï¼ˆè¾¹ç•ŒæŸå¤±ã€CPSæŸå¤±ç­‰ï¼‰
       c) æ€»æŸå¤±ï¼šL_total = L_sup + L_adv + L_FM + L_SOR + å…¶ä»–ï¼ˆè®ºæ–‡å…¬å¼(19)ï¼‰
       d) åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°
    
    å…³é”®æ¨¡å—ï¼š
    - CA (Coordinate Attention): ç¬¬3.3èŠ‚ï¼Œå¢å¼ºç©ºé—´å®šä½
    - SCD (Structure-Contrast Discriminator): ç¬¬3.2èŠ‚ï¼Œç»“æ„å¯¹æ¯”å­¦ä¹ 
    - SOR (Structure-Oriented Regularization): ç¬¬3.5èŠ‚ï¼Œç»“æ„ä¸€è‡´æ€§æ­£åˆ™åŒ–
    """
    # ========== æ•°æ®åŠ è½½ ==========
    train_l_data, train_u_data, valid_data = build_dataset(args)
    train_l_dataloader = DataLoader(train_l_data, args.batch_size, shuffle=True, num_workers=args.num_workers)
    train_u_dataloader = DataLoader(train_u_data, args.batch_size, shuffle=True, num_workers=args.num_workers)
    valid_sign = False
    if valid_data is not None:
        valid_sign = True
        valid_dataloader = DataLoader(valid_data, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)
        val_total_batch = math.ceil(len(valid_data) / args.batch_size)
    """load model"""
    model = build_model(args)
    scl_loss_fn = SemanticContrastiveLoss(temperature=0.1, momentum=0.9, num_classes=2)
    model_cps = build_model(args)  # Construct the CPS Branch Model
    model_cps.load_state_dict(model.state_dict())
    model_cps.eval()  # No second model is trained; it is only used to generate pseudo-labels.

    # ========== åˆå§‹åŒ–SCDåˆ¤åˆ«å™¨ï¼ˆè®ºæ–‡ç¬¬3.2èŠ‚ï¼‰ ==========
    if not args.no_scd:
        """
        Structure-Contrast Discriminator (SCD) åˆå§‹åŒ–
        è®ºæ–‡ç¬¬3.2èŠ‚ï¼šä½¿ç”¨DCGANé£æ ¼çš„åˆ¤åˆ«å™¨æ¶æ„
        
        è¾“å…¥è®¾è®¡ï¼š
        - è®ºæ–‡å…¬å¼(8): Z = Concat(F_u, B)ï¼Œå…¶ä¸­F_uæ˜¯512ç»´ç‰¹å¾ï¼ŒBæ˜¯1ç»´è¾¹ç•Œå›¾
        - ç†è®ºä¸Šè¾“å…¥é€šé“æ•°åº”ä¸º 512 + 1 = 513
        - ä¸ºä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨ç‰¹å¾é€‚é…å™¨å°†512ç»´é™ç»´åˆ°3ç»´
        - æœ€ç»ˆè¾“å…¥ï¼š3ï¼ˆç‰¹å¾ï¼‰+ 1ï¼ˆè¾¹ç•Œï¼‰= 4é€šé“ï¼Œå…¼å®¹é¢„è®­ç»ƒåˆ¤åˆ«å™¨
        """
        # åˆå§‹åŒ–åˆ¤åˆ«å™¨ï¼šDCGANæ¶æ„ï¼Œè¾“å…¥4é€šé“ï¼Œè¾“å‡º64x64ç‰¹å¾å›¾
        netD = DCGAN_D(isize=64, nz=100, nc=4, ndf=64, ngpu=1)
        netD.cuda()
        
        # ç‰¹å¾é€‚é…å™¨ï¼šå°†512ç»´ç¼–ç å™¨ç‰¹å¾é™ç»´åˆ°3ç»´
        # ç”¨äºå°†ç‰¹å¾-è¾¹ç•Œæ‹¼æ¥è¡¨ç¤ºé€‚é…åˆ°é¢„è®­ç»ƒåˆ¤åˆ«å™¨çš„è¾“å…¥æ ¼å¼
        feature_adapter = nn.Sequential(
            nn.Conv2d(512, 3, kernel_size=1, bias=False),  # 1x1å·ç§¯é™ç»´
            nn.BatchNorm2d(3),
            nn.ReLU(inplace=True)
        ).cuda()
        
        # åŠ è½½é¢„è®­ç»ƒçš„åˆ¤åˆ«å™¨æƒé‡ï¼ˆè®ºæ–‡æåˆ°åˆ¤åˆ«å™¨éœ€è¦é¢„è®­ç»ƒä»¥ç¨³å®šè®­ç»ƒï¼‰
        netD_weight = torch.load("models/pretrain/GAN/netD_epoch_10000.pth")
        new_state_dict = {}
        for k, v in netD_weight.items():
            # é€‚é…è¾“å…¥é€šé“æ•°ï¼šä»1é€šé“æ”¹ä¸º4é€šé“
            if k == "main.initial:1-64:conv.weight":
                print(f"Rename key: {k} -> main.initial:4-64:conv.weight")
                new_state_dict["main.initial:4-64:conv.weight"] = v
            else:
                new_state_dict[k] = v

        netD.load_state_dict(new_state_dict)
        netD.eval()  # åˆå§‹æ—¶è®¾ä¸ºè¯„ä¼°æ¨¡å¼
        
        # ç‰¹å¾é€‚é…å™¨çš„ä¼˜åŒ–å™¨ï¼ˆéœ€è¦å•ç‹¬ä¼˜åŒ–ï¼‰
        optim_adapter = torch.optim.Adam(feature_adapter.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    else:
        feature_adapter = None
        optim_adapter = None

    optim = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optim,
        T_0=10,
        T_mult=2,
        eta_min=1e-6
    )

    # train
    print('\n---------------------------------')
    print('Start training_semi')
    print('---------------------------------\n')
    F1_best, F1_second_best, F1_third_best = 0, 0, 0
    best = 0
    for epoch in range(args.nEpoch):
        model.train()
        print("Epoch: {}".format(epoch))
        loader = iter(zip(cycle(train_l_dataloader), train_u_dataloader))
        bar = tqdm(range(len(train_u_dataloader)))
        for batch_id in bar:
            data_l, data_u = next(loader)
            total_batch = len(train_u_dataloader)
            itr = total_batch * epoch + batch_id
            img_l, gt = data_l['image'], data_l['label']
            img_u = data_u
            if args.GPUs:
                img_l = img_l.cuda()
                gt = gt.cuda()
                img_u = img_u.cuda()
            # ========== å‰å‘ä¼ æ’­ï¼šæ ‡æ³¨æ•°æ® ==========
            optim.zero_grad()
            pred_l = model(img_l)
            # æ¨¡å‹è¾“å‡ºï¼š[mask, preboud, out2, out3, out4, out5, mask_binary, boundary_pred, e5]
            mask = pred_l[0]  # ä¸»åˆ†å‰²è¾“å‡º
            boundary_pred = pred_l[-2]  # è¾¹ç•Œé¢„æµ‹è¾“å‡º
            
            # è®¡ç®—æ ‡æ³¨æ•°æ®çš„ç›‘ç£æŸå¤±ï¼ˆè®ºæ–‡å…¬å¼(20)ï¼‰
            boundary_gt = get_boundary_map(gt)  # ä½¿ç”¨Sobelç®—å­æå–çœŸå®è¾¹ç•Œ
            loss_boundary = F.binary_cross_entropy_with_logits(boundary_pred, boundary_gt)
            loss_l_seg = DeepSupSeg(mask, gt)  # BCE + DiceæŸå¤±
            loss_l = loss_l_seg + 0.2 * loss_boundary  # ç›‘ç£æŸå¤±ï¼šåˆ†å‰²æŸå¤± + è¾¹ç•ŒæŸå¤±
            
            # ========== å‰å‘ä¼ æ’­ï¼šæ— æ ‡æ³¨æ•°æ® ==========
            pred_u = model(img_u)
            # è§£åŒ…è¾“å‡ºï¼špredboudæ˜¯è¾…åŠ©è§£ç å™¨è¾“å‡ºï¼Œfeat_uæ˜¯ç¼–ç å™¨ç‰¹å¾e5ï¼ˆç”¨äºSCDï¼‰
            _, predboud, sor_feat2, sor_feat3, sor_feat4, sor_feat5, mask_boud, _, feat_u = pred_u
            # feat_u = e5ï¼šç¼–ç å™¨æœ€æ·±å±‚çš„ç‰¹å¾ï¼ˆ512ç»´ï¼‰ï¼Œç”¨äºSCDçš„ç‰¹å¾F_uï¼ˆè®ºæ–‡ç¬¬3.2èŠ‚ï¼‰

            # ========== æ— æ ‡æ³¨æ•°æ®çš„åˆ†å‰²æŸå¤± ==========
            # ä½¿ç”¨ä¼ªæ ‡ç­¾ï¼ˆmask_boudï¼‰è¿›è¡Œç›‘ç£ï¼Œä½†é™ä½ä½ç½®ä¿¡åº¦åŒºåŸŸçš„æƒé‡
            with torch.no_grad():
                prob_map = torch.sigmoid(predboud)  # é¢„æµ‹æ¦‚ç‡å›¾
                weights = torch.ones_like(prob_map)
                # å¯¹ä½ç½®ä¿¡åº¦åŒºåŸŸï¼ˆ0.4-0.6ï¼‰é™ä½æƒé‡ï¼Œé¿å…å™ªå£°ä¼ªæ ‡ç­¾çš„å½±å“
                weights[(prob_map >= 0.4) & (prob_map <= 0.6)] = 0.5

            # åŠ æƒåˆ†å‰²æŸå¤±ï¼šé«˜ç½®ä¿¡åº¦åŒºåŸŸæƒé‡é«˜ï¼Œä½ç½®ä¿¡åº¦åŒºåŸŸæƒé‡ä½
            loss_u_seg = (DeepSupSeg(predboud, mask_boud) * weights).mean()

            # ========== è®­ç»ƒåˆ¤åˆ«å™¨Dï¼ˆSCDæ¨¡å— - è®ºæ–‡ç¬¬3.2èŠ‚ï¼‰ ==========
            if not args.no_scd:
                """
                Structure-Contrast Discriminator (SCD) - ç»“æ„å¯¹æ¯”åˆ¤åˆ«å™¨
                è®ºæ–‡ç¬¬3.2èŠ‚ï¼šé€šè¿‡å¯¹æŠ—å­¦ä¹ åŒºåˆ†çœŸå®å’Œä¼ªç»“æ„è¾¹ç•Œ
                
                æ ¸å¿ƒæ€æƒ³ï¼š
                1. æ„å»ºè”åˆè¡¨ç¤º Z = Concat(F_u, B)ï¼Œå…¶ä¸­ï¼š
                   - F_u: ç¼–ç å™¨æ·±å±‚ç‰¹å¾ï¼ˆe5ï¼Œ512ç»´ï¼‰
                   - B: é€šè¿‡Sobelç®—å­æå–çš„è¾¹ç•Œå›¾ï¼ˆè®ºæ–‡å…¬å¼(9)ï¼‰
                2. åˆ¤åˆ«å™¨å­¦ä¹ åŒºåˆ†çœŸå®è¾¹ç•Œï¼ˆæ¥è‡ªæ ‡æ³¨æ•°æ®ï¼‰å’Œä¼ªè¾¹ç•Œï¼ˆæ¥è‡ªæ— æ ‡æ³¨é¢„æµ‹ï¼‰
                3. é€šè¿‡å¯¹æŠ—è®­ç»ƒï¼Œå¼•å¯¼ç½‘ç»œç”Ÿæˆç»“æ„ä¸€è‡´çš„é¢„æµ‹
                
                è®ºæ–‡å…¬å¼(8): Z = Concat(F_u, B)
                è®ºæ–‡å…¬å¼(10)-(11): å¯¹æŠ—æŸå¤±
                """
                
                # ========== æ­¥éª¤1ï¼šæå–è¾¹ç•Œå›¾ï¼ˆè®ºæ–‡å…¬å¼(9)ï¼‰ ==========
                # ä½¿ç”¨Sobelç®—å­ä»æ©ç ä¸­æå–è¾¹ç•Œå›¾
                boundary_gt_l = get_boundary_sobel(gt)  # çœŸå®è¾¹ç•Œï¼šæ¥è‡ªæ ‡æ³¨æ•°æ®çš„ground truth
                boundary_pseudo_u = get_boundary_sobel(mask_boud)  # ä¼ªè¾¹ç•Œï¼šæ¥è‡ªæ— æ ‡æ³¨æ•°æ®çš„é¢„æµ‹
                
                # ========== æ­¥éª¤2ï¼šè·å–ç¼–ç å™¨ç‰¹å¾F_u ==========
                # å¯¹äºæ ‡æ³¨æ•°æ®ï¼šéœ€è¦é‡æ–°å‰å‘ä¼ æ’­è·å–ç¼–ç å™¨ç‰¹å¾
                with torch.no_grad():
                    _, _, _, _, _, _, _, _, feat_l = model(img_l)
                
                # å¯¹äºæ— æ ‡æ³¨æ•°æ®ï¼šfeat_uå·²ç»åœ¨å‰é¢è·å–ï¼ˆpred_uçš„æœ€åä¸€ä¸ªè¾“å‡ºï¼‰
                
                # ========== æ­¥éª¤3ï¼šè°ƒæ•´ç‰¹å¾å’Œè¾¹ç•Œå›¾çš„ç©ºé—´å°ºå¯¸ ==========
                # å°†ç‰¹å¾å›¾è°ƒæ•´åˆ°ä¸è¾¹ç•Œå›¾ç›¸åŒçš„ç©ºé—´å°ºå¯¸
                feat_l_resized = F.interpolate(feat_l, size=boundary_gt_l.shape[2:], mode='bilinear', align_corners=False)
                feat_u_resized = F.interpolate(feat_u, size=boundary_pseudo_u.shape[2:], mode='bilinear', align_corners=False)
                
                # ========== æ­¥éª¤4ï¼šç‰¹å¾é€‚é…ï¼ˆå…¼å®¹é¢„è®­ç»ƒåˆ¤åˆ«å™¨ï¼‰ ==========
                # å°†512ç»´ç‰¹å¾é™ç»´åˆ°3ç»´ï¼Œä»¥ä¾¿ä¸è¾¹ç•Œå›¾ï¼ˆ1ç»´ï¼‰æ‹¼æ¥æˆ4é€šé“è¾“å…¥
                # è¿™æ ·å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„åˆ¤åˆ«å™¨æƒé‡
                feat_l_adapted = feature_adapter(feat_l_resized.detach())
                feat_u_adapted = feature_adapter(feat_u_resized.detach())
                
                # ========== æ­¥éª¤5ï¼šæ„å»ºè”åˆç‰¹å¾-è¾¹ç•Œè¡¨ç¤ºï¼ˆè®ºæ–‡å…¬å¼(8)ï¼‰ ==========
                # Z = Concat(F, B)
                real_feat_boundary = torch.cat([feat_l_adapted, boundary_gt_l], dim=1)  # çœŸå®ï¼šZ_gt = (F_l, B(y))
                fake_feat_boundary = torch.cat([feat_u_adapted, boundary_pseudo_u], dim=1)  # ä¼ªï¼šZ_u = (F_u, B(P_u))
                
                # ========== æ­¥éª¤6ï¼šè®¡ç®—ç‰¹å¾åŒ¹é…æŸå¤±ï¼ˆè®ºæ–‡å…¬å¼(23)ï¼‰ ==========
                # L_FMç”¨äºç¨³å®šå¯¹æŠ—è®­ç»ƒï¼Œç¡®ä¿ç”Ÿæˆå™¨ç‰¹å¾ä¸çœŸå®ç‰¹å¾åœ¨åˆ¤åˆ«å™¨ä¸­é—´å±‚ç›¸ä¼¼
                # è®ºæ–‡æè¿°ï¼šç‰¹å¾åŒ¹é…æŸå¤±ä½¿æ¢¯åº¦ä¼ æ’­æ›´å¹³æ»‘
                _, real_features = netD(real_feat_boundary, return_features=True)
                _, fake_features = netD(fake_feat_boundary, return_features=True)

                fm_loss = 0
                # è®¡ç®—åˆ¤åˆ«å™¨å„å±‚ç‰¹å¾ä¹‹é—´çš„L1è·ç¦»
                for rf, ff in zip(real_features, fake_features):
                    fm_loss += F.l1_loss(ff, rf.detach())  # detachçœŸå®ç‰¹å¾ï¼Œé¿å…åå‘ä¼ æ’­åˆ°D
                fm_loss = fm_loss / len(real_features)  # å¤šå±‚ç‰¹å¾çš„å¹³å‡æŸå¤±
                # è®ºæ–‡æƒé‡ï¼šÎ»_FM = 1.0

                # ========== æ­¥éª¤7ï¼šè®­ç»ƒåˆ¤åˆ«å™¨ï¼ˆè®ºæ–‡å…¬å¼(21)-(22)ï¼‰ ==========
                criterion_GAN = nn.BCEWithLogitsLoss()
                
                # åˆ¤åˆ«å™¨å‰å‘ä¼ æ’­ï¼šåŒºåˆ†çœŸå®å’Œä¼ªè¾¹ç•Œ
                real_pred = netD(real_feat_boundary)  # çœŸå®è¾¹ç•Œåº”è¯¥è¾“å‡º1
                fake_pred = netD(fake_feat_boundary)  # ä¼ªè¾¹ç•Œåº”è¯¥è¾“å‡º0
                real_labels = torch.ones_like(real_pred)
                fake_labels = torch.zeros_like(fake_pred)

                # è®¡ç®—åˆ¤åˆ«å™¨æŸå¤±ï¼ˆè®ºæ–‡å…¬å¼(22)ï¼‰
                errD_real = criterion_GAN(real_pred, real_labels)  # çœŸå®è¾¹ç•ŒæŸå¤±
                errD_fake = criterion_GAN(fake_pred, fake_labels)  # ä¼ªè¾¹ç•ŒæŸå¤±
                errD = (errD_real + errD_fake) * 0.5  # æ€»åˆ¤åˆ«å™¨æŸå¤±

                # æ›´æ–°åˆ¤åˆ«å™¨å‚æ•°ï¼ˆæ¯2ä¸ªepochæ›´æ–°ä¸€æ¬¡ï¼Œç¨³å®šè®­ç»ƒï¼‰
                netD.train()
                optimizer_D = torch.optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.999))
                if epoch % 2 == 0:
                    optimizer_D.zero_grad()
                    errD.backward()
                    optimizer_D.step()

            # ---------------- edge loss ----------------
            if not args.no_scd:
                loss_edge = edge_loss(predboud, mask_boud)
            else:
                loss_edge = torch.tensor(0.0, device=img_u.device)

            # ========== ç”Ÿæˆå™¨å¯¹æŠ—æŸå¤±ï¼ˆSCD - è®ºæ–‡å…¬å¼(21)ï¼‰ ==========
            if not args.no_scd:
                """
                ç”Ÿæˆå™¨æŸå¤±ï¼šå¼•å¯¼ç½‘ç»œç”Ÿæˆç»“æ„ä¸€è‡´çš„é¢„æµ‹
                è®ºæ–‡å…¬å¼(21): L_adv = E_{x_u}[-log(1 - D(Z_u))]
                ç›®æ ‡ï¼šä½¿ä¼ªè¾¹ç•Œè¢«åˆ¤åˆ«å™¨è¯¯åˆ¤ä¸ºçœŸå®è¾¹ç•Œï¼ˆè¾“å‡ºæ¥è¿‘1ï¼‰
                """
                # æå–æ— æ ‡æ³¨æ•°æ®çš„è¾¹ç•Œå›¾
                boundary_pseudo_u = get_boundary_sobel(mask_boud)
                
                # å¯¹äºç”Ÿæˆå™¨ï¼šä½¿ç”¨å½“å‰ç‰¹å¾ï¼ˆä¸detachï¼‰ï¼Œå…è®¸æ¢¯åº¦åå‘ä¼ æ’­
                feat_u_resized_G = F.interpolate(feat_u, size=boundary_pseudo_u.shape[2:], mode='bilinear', align_corners=False)
                feat_u_adapted_G = feature_adapter(feat_u_resized_G)
                fake_feat_boundary_G = torch.cat([feat_u_adapted_G, boundary_pseudo_u], dim=1)
                
                # ç”Ÿæˆå™¨å¸Œæœ›åˆ¤åˆ«å™¨å°†ä¼ªè¾¹ç•Œåˆ¤æ–­ä¸ºçœŸå®ï¼ˆè¾“å‡ºæ¥è¿‘1ï¼‰
                pred_fake_for_G = netD(fake_feat_boundary_G)
                errG_adv = criterion_GAN(pred_fake_for_G, real_labels)
                # è®ºæ–‡æƒé‡ï¼šÎ»_adv = 0.1
            else:
                errG_adv = torch.tensor(0.0, device=img_u.device)
                fm_loss = torch.tensor(0.0, device=img_u.device)

            # ========== SORæŸå¤±ï¼ˆç»“æ„å¯¼å‘æ­£åˆ™åŒ– - è®ºæ–‡ç¬¬3.5èŠ‚ï¼‰ ==========
            if not args.no_sor:
                """
                Structure-Oriented Regularization (SOR) - ç»“æ„å¯¼å‘æ­£åˆ™åŒ–
                è®ºæ–‡ç¬¬3.5èŠ‚ï¼šé€šè¿‡ç»“æ„çº§ä¸€è‡´æ€§çº¦æŸå¢å¼ºæ¨¡å‹å¯¹è¾¹ç•Œæ¨¡ç³Šçš„é²æ£’æ€§
                
                æ ¸å¿ƒæ€æƒ³ï¼š
                1. å¯¹è§£ç å™¨è¾“å‡ºæ–½åŠ dropoutæ‰°åŠ¨ï¼Œç”Ÿæˆæ‰°åŠ¨è§†å›¾
                2. ä½¿ç”¨Sobelç®—å­æå–ç»“æ„è¡¨ç¤ºï¼ˆè¾¹ç•Œå›¾ï¼‰
                3. æœ€å°åŒ–å¹²å‡€é¢„æµ‹å’Œæ‰°åŠ¨é¢„æµ‹çš„ç»“æ„è¡¨ç¤ºå·®å¼‚
                4. ç¡®ä¿æ¨¡å‹åœ¨è§£ç å™¨æ‰°åŠ¨ä¸‹ä»èƒ½ä¿æŒç»“æ„ä¸€è‡´æ€§
                
                è®ºæ–‡å…¬å¼(17): s = G(p), s_hat = G(p_hat)ï¼Œå…¶ä¸­Gæ˜¯Sobelç®—å­
                è®ºæ–‡å…¬å¼(18): L_SOR = Î»_SOR * ||s - s_hat||_1
                """
                
                # ========== æ­¥éª¤1ï¼šå¯¹è§£ç å™¨è¾“å‡ºæ–½åŠ æ‰°åŠ¨ ==========
                decoder_output_clean = predboud  # å¹²å‡€é¢„æµ‹ï¼ˆæ— æ‰°åŠ¨ï¼‰
                decoder_output_perturbed = F.dropout2d(decoder_output_clean, p=0.1, training=True)  # æ‰°åŠ¨é¢„æµ‹
                
                # ========== æ­¥éª¤2ï¼šæå–ç»“æ„è¡¨ç¤ºï¼ˆè®ºæ–‡å…¬å¼(17)ï¼‰ ==========
                # ä½¿ç”¨Sobelç®—å­ä»é¢„æµ‹ä¸­æå–ç»“æ„è¾¹ç•Œè¡¨ç¤º
                # s = G(p)ï¼šå¹²å‡€é¢„æµ‹çš„ç»“æ„è¡¨ç¤º
                struct_clean = get_boundary_sobel(torch.sigmoid(decoder_output_clean))
                # s_hat = G(p_hat)ï¼šæ‰°åŠ¨é¢„æµ‹çš„ç»“æ„è¡¨ç¤º
                struct_perturbed = get_boundary_sobel(torch.sigmoid(decoder_output_perturbed))
                
                # ========== æ­¥éª¤3ï¼šè®¡ç®—ç»“æ„ä¸€è‡´æ€§æŸå¤±ï¼ˆè®ºæ–‡å…¬å¼(18)ï¼‰ ==========
                # L_SOR = Î»_SOR * ||s - s_hat||_1
                # æœ€å°åŒ–å¹²å‡€å’Œæ‰°åŠ¨é¢„æµ‹çš„ç»“æ„å·®å¼‚ï¼Œå¢å¼ºç»“æ„ç¨³å®šæ€§
                loss_sor = 0.2 * F.l1_loss(struct_clean, struct_perturbed)
                # è®ºæ–‡æƒé‡ï¼šÎ»_SOR = 0.2
            else:
                loss_sor = torch.tensor(0.0, device=img_u.device)

            # ---------------- Additional losses (only when SCD is enabled) ----------------
            if not args.no_scd:
                # ========== Semantic Contrastive Loss ==========
                sor_feat4 = F.normalize(sor_feat4, p=2, dim=1)
                feat4 = sor_feat4
                label4 = F.interpolate(mask_boud, size=feat4.shape[2:], mode='nearest').squeeze(1).long()
                scl_weight = sigmoid_rampup(epoch, 20) * 0.1
                loss_scl = scl_weight * scl_loss_fn(feat4, label4)

                # ========== Prototype Matching Soft Pseudo Label ==========
                features = torch.cat([
                    F.interpolate(sor_feat3, size=sor_feat4.shape[2:], mode='bilinear', align_corners=False),
                    sor_feat4
                ], dim=1)
                logits = predboud.detach()

                with torch.no_grad():
                    probs = torch.sigmoid(logits)
                    conf_mask = ((probs > 0.3) & (probs < 0.7)).float()
                    probs_bin = (probs > 0.5).float() * (1 - conf_mask)  # Clear the blurred area
                    probs_bin_down = F.interpolate(probs_bin, size=(features.shape[2], features.shape[3]),
                                                   mode='bilinear', align_corners=False)

                    B, C, H, W = features.size()
                    features_flat = features.view(B, C, -1)
                    probs_flat = probs_bin_down.view(B, 1, -1)

                    eps = 1e-6
                    foreground_proto = (features_flat * probs_flat).sum(dim=2) / (probs_flat.sum(dim=2) + eps)
                    background_proto = (features_flat * (1 - probs_flat)).sum(dim=2) / (
                                (1 - probs_flat).sum(dim=2) + eps)

                    feat_norm = F.normalize(features_flat, dim=1)
                    fg_proto = F.normalize(foreground_proto.unsqueeze(2), dim=1)
                    bg_proto = F.normalize(background_proto.unsqueeze(2), dim=1)

                    fg_sim = torch.bmm(fg_proto.transpose(1, 2), feat_norm).squeeze(1)
                    bg_sim = torch.bmm(bg_proto.transpose(1, 2), feat_norm).squeeze(1)

                    sim_stack = torch.stack([bg_sim, fg_sim], dim=1)
                    soft_label = F.softmax(sim_stack, dim=1)[:, 1]
                    soft_label = soft_label.view(B, 1, H, W)

                soft_label_up = F.interpolate(soft_label, size=predboud.shape[2:], mode='bilinear', align_corners=False)
                loss_soft_pseudo = scl_weight * F.binary_cross_entropy_with_logits(predboud, soft_label_up)

            if args.no_scd:
                loss_edge = dynamic_edge_loss(predboud, mask_boud, epoch=epoch, total_epoch=args.nEpoch)
                loss = 2 * loss_l + 0.5 * loss_u_seg
                loss.mean().backward()
                optim.step()

            if not args.no_scd:
                # Obtain pseudo-labels using model_cps (without backpropagating gradients)
                with torch.no_grad():
                    pred_u_cps = model_cps(img_u)[0]
                    pseudo_u_cps = (torch.sigmoid(pred_u_cps) > 0.5).float()

                # ------------------- ğŸ”¹ NEW: Uncertainty-weighted consistency -------------------
                prob_u_main = torch.sigmoid(predboud).clamp(1e-6, 1 - 1e-6)
                entropy_u = - (prob_u_main * torch.log(prob_u_main) + (1 - prob_u_main) * torch.log(1 - prob_u_main))
                uncertainty_weight = 1 - entropy_u / math.log(2)  # é«˜ä¸ç¡®å®šæ€§åŒºåŸŸæƒé‡ä½
                # -----------------------------------------------------------------------------

                # Align the predictions of the main model with the pseudo-labels to calculate the consistency loss.
                pred_u_main = predboud  # The output of your main model
                loss_cps = (F.binary_cross_entropy_with_logits(pred_u_main, pseudo_u_cps, reduction='none') * uncertainty_weight.detach()).mean()

                # ========== æ€»æŸå¤±å‡½æ•°ï¼ˆè®ºæ–‡ç¬¬3.6èŠ‚ï¼Œå…¬å¼(19)ï¼‰ ==========
                """
                è®ºæ–‡å…¬å¼(19): L_total = L_sup + Î»_adv * L_adv + Î»_FM * L_FM + Î»_SOR * L_SOR
                
                æŸå¤±ç»„ä»¶ï¼š
                - L_sup: ç›‘ç£æŸå¤±ï¼ˆBCE + Diceï¼‰ï¼Œç”¨äºæ ‡æ³¨æ•°æ®
                - L_adv: å¯¹æŠ—æŸå¤±ï¼ˆSCDï¼‰ï¼Œæƒé‡Î»_adv=0.1
                - L_FM: ç‰¹å¾åŒ¹é…æŸå¤±ï¼ˆSCDï¼‰ï¼Œæƒé‡Î»_FM=1.0
                - L_SOR: ç»“æ„å¯¼å‘æ­£åˆ™åŒ–æŸå¤±ï¼Œæƒé‡Î»_SOR=0.2
                """
                cps_weight = sigmoid_rampup(epoch, rampup_length=10)
                
                # æ— æ ‡æ³¨æ•°æ®çš„æŸå¤±ç»„åˆ
                loss_u = (
                        0.75 * loss_u_seg +        # æ— æ ‡æ³¨åˆ†å‰²æŸå¤±
                        0.1 * errG_adv +          # Î»_adv * L_advï¼ˆè®ºæ–‡æƒé‡0.1ï¼‰
                        1.0 * fm_loss +           # Î»_FM * L_FMï¼ˆè®ºæ–‡æƒé‡1.0ï¼‰
                        0.2 * loss_sor +         # Î»_SOR * L_SORï¼ˆè®ºæ–‡æƒé‡0.2ï¼‰
                        0.05 * loss_edge +        # è¾¹ç•ŒæŸå¤±ï¼ˆè¾…åŠ©ï¼‰
                        cps_weight * loss_cps +   # CPSä¸€è‡´æ€§æŸå¤±ï¼ˆåŠ¨æ€æƒé‡ï¼‰
                        0.05 * loss_scl +         # è¯­ä¹‰å¯¹æ¯”æŸå¤±ï¼ˆè¾…åŠ©ï¼‰
                        0.05 * loss_soft_pseudo   # è½¯ä¼ªæ ‡ç­¾æŸå¤±ï¼ˆè¾…åŠ©ï¼‰
                )

                # æ€»æŸå¤±ï¼šL_total = L_sup + L_u
                # å…¶ä¸­L_supåŒ…å«ç›‘ç£æŸå¤±å’Œè¾¹ç•ŒæŸå¤±ï¼ŒL_uåŒ…å«æ‰€æœ‰æ— æ ‡æ³¨æŸå¤±ç»„ä»¶
                loss = loss_l + loss_u
                loss.mean().backward()
                optim.step()
                if not args.no_scd and optim_adapter is not None:
                    optim_adapter.step()

            adjust_lr_rate(optim, itr, total_batch)
        model.eval()
        if valid_sign == True:
            recall, specificity, precision, F1, F2, \
                ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice, *_ = evaluate(model, valid_dataloader, val_total_batch)
            save_output = False
            if dice > best:
                best = dice
                save_output = True
            print("Best Dice:: ", best)

            if save_output:
                result_dir = './result'
                if os.path.exists(result_dir):
                    shutil.rmtree(result_dir)
                os.makedirs(result_dir)
                evaluate(model, valid_dataloader, val_total_batch, save_best=True)

            print("Valid Result:")
            print(
                'recall: %.4f, specificity: %.4f, precision: %.4f, F1: %.4f, F2: %.4f, ACC_overall: %.4f, IoU_poly: %.4f, IoU_bg: %.4f, IoU_mean: %.4f, dice: %.4f' \
                % (recall, specificity, precision, F1, F2, ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice))

            scheduler.step()
            if (F1 > F1_best):
                F1_best = F1
                torch.save(model.state_dict(), args.root + "/semi/checkpoint/" + args.ckpt_name + "/best.pth")
            elif (F1 > F1_second_best):
                F1_second_best = F1
                torch.save(model.state_dict(), args.root + "/semi/checkpoint/" + args.ckpt_name + "/second_best.pth")
            elif (F1 > F1_third_best):
                F1_third_best = F1
                torch.save(model.state_dict(), args.root + "/semi/checkpoint/" + args.ckpt_name + "/third_best.pth")


def test():
    print('loading data......')
    test_data = build_dataset(args)
    test_dataloader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)
    total_batch = math.ceil(len(test_data) / args.batch_size)
    model = build_model(args)
    if args.GPUs:
        model = model.cuda()
    # ä¼˜å…ˆåŠ è½½ teacher çš„ bestï¼›æ²¡æœ‰å°±å›é€€ student çš„ bestï¼›å†æ²¡æœ‰å°±ç”¨éšæœºåˆå§‹åŒ–
    ckpt_dir_stu = os.path.join(args.root, "semi", "checkpoint", args.ckpt_name)
    ckpt_dir_tch = os.path.join(args.root, "semi", "checkpoint", args.ckpt_name + "_teacher")
    pth_tch = os.path.join(ckpt_dir_tch, "best.pth")
    pth_stu = os.path.join(ckpt_dir_stu, "best.pth")

    if os.path.exists(pth_tch):
        print(f"[Test] Loading EMA-Teacher checkpoint: {pth_tch}")
        model.load_state_dict(torch.load(pth_tch, map_location="cpu"))
    elif os.path.exists(pth_stu):
        print(f"[Test] Loading Student checkpoint: {pth_stu}")
        model.load_state_dict(torch.load(pth_stu, map_location="cpu"))
    else:
        print("[Test] WARNING: no checkpoint found; testing with randomly initialized weights.")

    model.eval()

    recall, specificity, precision, F1, F2, \
        ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice, _, _, table_metrics = \
        evaluate(model, test_dataloader, total_batch, spacing=(0.07, 0.07))

    if args.dataset.lower() == "hc18":
        # HC18 æ‰“å°ç²¾ç®€ç‰ˆ
        print(
            'Valid Result: recall: %.4f, specificity: %.4f, precision: %.4f, F1: %.4f, F2: %.4f, '
            'ACC_overall: %.4f, IoU_poly: %.4f, IoU_bg: %.4f, IoU_mean: %.4f, dice: %.4f, '
            'DSC_all: %.4f, Jacc_all: %.4f, HD95_all: %.4f, ASD_all: %.4f'
            % (recall, specificity, precision, F1, F2,
               ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice,
               table_metrics['DSC'], table_metrics['Jaccard'],
               table_metrics['HD95'], table_metrics['ASD'])
        )
    else:
        # å…¶ä»–æ•°æ®é›†ï¼ˆä¾‹å¦‚ PSFHï¼‰æ‰“å°å…¨æŒ‡æ ‡
        print(
            'Valid Result: recall: %.4f, specificity: %.4f, precision: %.4f, F1: %.4f, F2: %.4f, '
            'ACC_overall: %.4f, IoU_poly: %.4f, IoU_bg: %.4f, IoU_mean: %.4f, dice: %.4f, '
            'DSC_all: %.4f, Jacc_all: %.4f, HD95_all: %.4f, ASD_all: %.4f, '
            'DSC_PS: %.4f, Jacc_PS: %.4f, HD95_PS: %.4f, ASD_PS: %.4f, '
            'DSC_FH: %.4f, Jacc_FH: %.4f, HD95_FH: %.4f, ASD_FH: %.4f'
            % (recall, specificity, precision, F1, F2,
               ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice,
               table_metrics['DSC'], table_metrics['Jaccard'], table_metrics['HD95'], table_metrics['ASD'],
               table_metrics['DSC_PS'], table_metrics['Jaccard_PS'], table_metrics['HD95_PS'], table_metrics['ASD_PS'],
               table_metrics['DSC_FH'], table_metrics['Jaccard_FH'], table_metrics['HD95_FH'], table_metrics['ASD_FH'])
        )


if __name__ == '__main__':

    checkpoint_name = os.path.join(args.root, 'semi/checkpoint/' + args.ckpt_name)
    if not os.path.exists(checkpoint_name):
        os.makedirs(checkpoint_name)
    else:
        pass

    os.environ['CUDA_VISIBLE_DEVICES'] = args.GPUs
    if args.manner == 'full':
        print('---{}-Seg Train---'.format(args.dataset))
        train()
    elif args.manner == 'semi':
        print('---{}-seg Semi-Train--'.format(args.dataset))
        train_semi()
    elif args.manner == 'test':
        print('---{}-Seg Test---'.format(args.dataset))
        test()
    print('Done')

